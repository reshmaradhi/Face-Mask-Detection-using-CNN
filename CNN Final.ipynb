{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff42b647-3a7a-414b-945b-ba6acace635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\reshm\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eef8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa12dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2df856",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_vgg16_conv.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f247d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "train_data_dir = \"C:/Users/reshm/Downloads/archive (3)/dataset/dataset/train\"\n",
    "val_data_dir = \"C:/Users/reshm/Downloads/archive (3)/dataset/dataset/train\"\n",
    "model_weights_file = 'vgg16-xfer-weights.h5'\n",
    "nb_train_samples = 4\n",
    "nb_val_samples = 4\n",
    "nb_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de99a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(img_width, img_height, 3))\n",
    "output_vgg16_conv = model_vgg16_conv(input)\n",
    "x = Flatten()(output_vgg16_conv)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "model = Model(input, x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a032ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3064 images belonging to 2 classes.\n",
      "Found 3064 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#augment  images\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height),\n",
    "                                                    batch_size=4, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height),\n",
    "                                                        batch_size=4,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408ea0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9347WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "766/766 [==============================] - 257s 335ms/step - loss: 0.1812 - accuracy: 0.9347 - val_loss: 0.0472 - val_accuracy: 0.9830\n",
      "Epoch 2/5\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9719WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "766/766 [==============================] - 278s 363ms/step - loss: 0.0894 - accuracy: 0.9719 - val_loss: 0.0331 - val_accuracy: 0.9896\n",
      "Epoch 3/5\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "766/766 [==============================] - 280s 365ms/step - loss: 0.0753 - accuracy: 0.9775 - val_loss: 0.0295 - val_accuracy: 0.9922\n",
      "Epoch 4/5\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "766/766 [==============================] - 278s 363ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9860WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "766/766 [==============================] - 277s 362ms/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.0670 - val_accuracy: 0.9840\n",
      "Training Completed!\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history = model.fit_generator( train_generator, epochs=5, callbacks = callbacks, validation_data=validation_generator)\n",
    "print('Training Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d14795a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 150, 150, 3)\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Predicted Array: [[1. 0.]]\n",
      "Predicted Label: mask\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "#img_path = \"C:/Users/reshm/Downloads/archive (3)/dataset/dataset/test/without_mask/340.jpg\"\n",
    "#img_path = r\"C:\\Users\\reshm\\OneDrive\\Pictures\\IMG-20210420-WA0000.jpg\" #withoutmask\n",
    "img_path = r\"C:\\Users\\reshm\\OneDrive\\Pictures\\IMG-20210904-WA0006.jpeg\" #mask\n",
    "label = ['mask', 'no mask']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print('Input Shape:', x.shape)\n",
    "\n",
    "features = model.predict(x)\n",
    "\n",
    "print('Predicted Array:', features)\n",
    "\n",
    "if features.size > 0:\n",
    "    ind = np.argmax(features)  # Using np.argmax instead of np.where\n",
    "    print('Predicted Label:', label[ind])\n",
    "else:\n",
    "    print('No predictions were made.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c030f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 150, 150, 3)\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Predicted Array: [[1. 0.]]\n",
      "Predicted Label: mask\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"C:/Users/reshm/Downloads/archive (3)/dataset/dataset/test/with_mask/with_mask621.jpeg\"\n",
    "label = ['mask', 'no mask']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print('Input Shape:', x.shape)\n",
    "\n",
    "features = model.predict(x)\n",
    "\n",
    "print('Predicted Array:', features)\n",
    "\n",
    "if features.size > 0:\n",
    "    ind = np.argmax(features)  # Using np.argmax instead of np.where\n",
    "    print('Predicted Label:', label[ind])\n",
    "else:\n",
    "    print('No predictions were made.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ce90a-9aab-4dc7-b1c3-e0a3b83fc0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
